{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageBasedDataMining.ipynb\n",
    "‹ ImageBasedDataMining.ipynb › Copyright (C) ‹ 2018 › ‹ Andrew Green - andrew.green-2@manchester.ac.uk › This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/.\n",
    "\n",
    "---\n",
    "\n",
    "18052018    afg    First version, converted from python script for JEDI MadagaSKA\n",
    "\n",
    "---\n",
    "\n",
    "This notebook shows how to do image based data mining against a binary outcome, in this case looking for a relationship between radiation dose and whether a patient needed a feeding tube inserted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a class that wraps around the outcome/clinical data (which is in a big .csv file). This allows us to query the data for whatever variables we need to.\n",
    "\n",
    "This is not efficient, but should only need to be done a few times, so nevermind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "class HNSCCOutcomes:\n",
    "    def __init__(self):\n",
    "        self.csvFileName = \"/data/projects/idmrct/hnscc/HNSCC-ClinData_date_offset.csv\"\n",
    "\n",
    "\n",
    "    def findPatient(self, patID):\n",
    "        with open(self.csvFileName, 'r') as hnData:\n",
    "            self.reader = csv.DictReader(hnData, fieldnames=[\"TCIA code\",\"Sex\",\"Age\", \"Date of Birth\", \"Diag\", \"Site\", \"Histology\", \"Grade\",\"T\",\"N\",\"M\",\n",
    "                                                        \"Stage\", \"Date of Diagnosis\", \"Last Contact Date\", \"Follow up duration (day)\", \"Follow up duration (year)\",\n",
    "                                                        \"Follow up duration (month)\", \"Date of Death\", \"Survival  (months)\", \"Alive or Dead\",\n",
    "                                                        \"Cause of Death\", \"Date of recurrence\", \"Disease-free interval (months)\", \"Site of recurrence (Distal/Local/ Locoregional)\", \"Overall Survival Censor\",\n",
    "                                                        \"Disease Specific Survival Censor\", \"Loco-regional Control Censor\", \"Oncologic Treatment Summary\", \"Induction Chemotherapy\", \"Chemotherapy Regimen\",\n",
    "                                                        \"Platinum-based chemotherapy\", \"Received Concurrent Chemoradiotherapy?\", \"CCRT Chemotherapy Regimen\", \"Surgery Summary\", \"RT Total Dose (Gy)\", \"Dose/Fraction (Gy/fx)\",\n",
    "                                                        \"Number of Fractions\", \"Unplanned Additional Oncologic Treatment\", \"Smoking History\", \"Current Smoker\", \"Received Feeding Tube (Y/N)\", \"Type of feeding tube\", \"Date Feeding tube placed\",\n",
    "                                                        \"Date Feeding tube removed\", \"Feeding tube duration (months)\", \"Feeding tube note\", \"Height (cm)\", \"BW Start tx (kg)\",\" BW stop treat (kg)\", \"Height (m)\", \n",
    "                                                        \"BMI start treat (kg/m2)\", \"BMI stop treat (kg/m2)\", \"Date Start RT\", \"Date Stop RT\", \"Total RT treatment time (days)\", \"Time between pre and post image (months)\", \n",
    "                                                        \"Time from preRT image to start RT (month)\", \"Time from RT stop to follow up imaging (months)\", \"Pre-RT L3 Skeletal Muscle Cross Sectional Area (cm2)\", \n",
    "                                                        \"Post-RT L3 Skeletal Muscle Cross Sectional Area (cm2)\", \"Pre-RT L3 Adipose Tissue Cross Sectional Area (cm2)\", \"Post-RT L3 Adipose Tissue Cross Sectional Area (cm2)\", \n",
    "                                                        \"Pre-RT L3 Skeletal Muscle Index (cm2/m2)\", \"Post-RT L3 Skeletal Muscle Index (cm2/m2)\", \"Pre-RT L3 Adiposity Index (cm2/m2)\", \"Post-RT L3 Adiposity Index (cm2/m2)\"\n",
    "                                                        \"Pre-RT CT-derived lean body mass (kg)\", \"Post-RT CT-derived lean body mass (kg)\", \"Pre-RT CT-derived fat body mass (kg)\", \"Post-RT CT-derived fat body mass (kg)\", \n",
    "                                                        \"PreRT Skeletal Muscle status\", \"PostRT Skeletal Muscle status\"])\n",
    "            for row in self.reader:\n",
    "                if re.search(patID, row[\"TCIA code\"]):\n",
    "                    return row\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "One of the probelms with our data is that it is very messy. We need to exclude a lot of patients who have other things that might make them need a feeding tube. In the next cell, we filter the data so we only have patients who got the same number of fractions, and had the same type of treatment (i.e. radiotherapy without surgery first, and similar chemotherapy).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = HNSCCOutcomes()\n",
    "\n",
    "\"\"\"\n",
    "Exlude:\n",
    "- pre-RT surgery\n",
    "- Weird fractionations (i.e. all pt with 40 fx)\n",
    "- Induction chemo\n",
    "- CCRT + immuno.\n",
    "\"\"\"\n",
    "\n",
    "ptsToUse = []\n",
    "statuses = []\n",
    "\n",
    "eligible = 0\n",
    "events = 0\n",
    "status = 0\n",
    "\n",
    "nrrOutputDoses = \"/data/projects/idmrct/hnscc/deformedDose\"\n",
    "files = os.listdir(nrrOutputDoses)\n",
    "\n",
    "for f in files:\n",
    "    ID = f.split('.')[0]\n",
    "    summary = outcomes.findPatient(ID)[\"Oncologic Treatment Summary\"]\n",
    "    pegStatus = outcomes.findPatient(ID)[\"Type of feeding tube\"]\n",
    "    \n",
    "    # series of negative filters\n",
    "    if not summary.startswith(\"CCRT\"): ## Miss any surgery/induction chemo\n",
    "        continue\n",
    "    elif re.search(\"\\+\", summary):## Miss any immunotherapy\n",
    "        continue\n",
    "    elif outcomes.findPatient(ID)[\"Number of Fractions\"] == \"40\":## Skip weird fractionation\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    eligible += 1\n",
    "    if pegStatus == \"PEG\":\n",
    "        events += 1\n",
    "        status = 1\n",
    "    else:\n",
    "        status = 0\n",
    "\n",
    "    ptsToUse.append(ID)\n",
    "    statuses.append(status)\n",
    "    print(summary, outcomes.findPatient(ID)[\"Number of Fractions\"], pegStatus)\n",
    "\n",
    "print(eligible, events)\n",
    "\n",
    "ptsToUse = np.array(ptsToUse)\n",
    "statuses = np.array(statuses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different fractionations have diferent effects because of the different amount of time normal tissue has to recover. Before we can mine data with different fractionations, we need to standardize somehow. This is usually done with a biologically equivalent dose (BED) calculation, or an equivalent dose @ 2 Gy/fraction (EQD2) calculation. Here we will do a simple BED calculation, whereby we just multiply the real dose by a factor to take account of the differences in fractionation.\n",
    "\n",
    "Also, whether we want to look at 'acute effects' (i.e. things that happen soon) or 'late effects' (i.e. things that happen after a few weeks/months). the way these differences come into the BED calculation is in an $\\alpha/\\beta$ ratio. A ratio of $\\alpha/\\beta$ = 3.0 is usual when considering late effects. I have a hunch that the requirement for a feeding tube is probably an acute effect, in which case an $\\alpha/\\beta$ ratio of 10 is more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyAlphaBeta = 10.0\n",
    "lateAlphaBeta  = 03.0\n",
    "\n",
    "bedDoses = \"/data/projects/idmrct/hnscc/bedCorrectedDoses\"\n",
    "\n",
    "for ID in ptsToUse:\n",
    "    fractionDose = float(outcomes.findPatient(ID)[\"Dose/Fraction (Gy/fx)\"])\n",
    "    \n",
    "    BEDfactor = 1.0 + fractionDose/earlyAlphaBeta ## Note, here we assume that feeding tube insertion is an early effect\n",
    "    \n",
    "    thisDose = sitk.ReadImage(os.path.join(nrrOutputDoses, \"{0:04d}.nii\".format(int(ID))))\n",
    "    thisDose *= BEDfactor\n",
    "    sitk.WriteImage(thisDose, os.path.join(bedDoses, \"{0:04d}.nii\".format(int(ID))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have corrected for the fractionation, we are ready to do mine the data. To do this, we define a couple of helper functions.\n",
    "\n",
    "imagesTTest performs a voxel-wise t-test between the two groups, using [Welford's method](https://www.johndcook.com/blog/standard_deviation/) to calculate the mean and variance on the fly.\n",
    "\n",
    "The doPermutation function performs a single permutation of the label data, we will use it to assess the statistical significance of what we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPermutation(doseData, statuses):\n",
    "    pstatuses = np.random.permutation(statuses)\n",
    "    permT = imagesTTest(doseData, pstatuses)\n",
    "    return np.max(permT)\n",
    "\n",
    "def imagesTTest(doseData, statuses):#\n",
    "    imageShape = doseData.shape\n",
    "\n",
    "    noPEGmean = np.zeros_like(doseData[:,:,:,0])\n",
    "    PEGmean = np.zeros_like(doseData[:,:,:,0]) + np.finfo(float).eps\n",
    "\n",
    "    noPEGstd = np.zeros_like(doseData[:,:,:,0])\n",
    "    PEGstd = np.zeros_like(doseData[:,:,:,0]) + np.finfo(float).eps\n",
    "\n",
    "    pegCount = 0\n",
    "    noPegCount = 0\n",
    "    for n, stat in enumerate(statuses):\n",
    "        if stat == 1 and pegCount == 0:\n",
    "            pegCount += 1.0\n",
    "            PEGmean = doseData[:,:,:,n]\n",
    "        elif stat == 1:\n",
    "            pegCount += 1.0\n",
    "            om = PEGmean#.copy()\n",
    "            PEGmean = om - (doseData[:,:,:,n] - om)/pegCount\n",
    "            PEGstd = PEGstd + (doseData[:,:,:,n] - om)*(doseData[:,:,:,n] - PEGmean)\n",
    "        elif stat == 0 and noPegCount == 0:\n",
    "            noPegCount += 1.0\n",
    "            noPEGmean = doseData[:,:,:,n]\n",
    "        elif stat == 0:\n",
    "            noPegCount += 1.0\n",
    "            om = noPEGmean#.copy()\n",
    "            noPEGmean = om - (doseData[:,:,:,n] - om)/noPegCount\n",
    "            noPEGstd = noPEGstd + (doseData[:,:,:,n] - om)*(doseData[:,:,:,n] - noPEGmean)\n",
    "            \n",
    "    pegTTest = (PEGmean - noPEGmean)/np.sqrt(PEGstd + noPEGstd)\n",
    "\n",
    "    return pegTTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the actual data mining. We load all the BED doses and stack them into a single numpy array. We then mask out only the region where we did registration (because we hope the registration is ok there).\n",
    "\n",
    "Then we do a per-voxel t-test and a permutation test to assess significance. The permutation test will take quite a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell generates the indices where we will crop the full resolution array. We can then use a much smaller array\n",
    "to do the calculation, which makes the permutation testing about 50x faster\n",
    "\"\"\"\n",
    "masks = \"/data/projects/idmrct/hnscc/niftyMasks\"\n",
    "regionMask = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(masks, \"0001.nii\")))\n",
    "\n",
    "idxs0_0 = np.where(regionMask > 0)[0][0]\n",
    "idxs0_1 = np.where(regionMask > 0)[0][-1]\n",
    "\n",
    "idxs1_0 = np.where(regionMask > 0)[1][0]\n",
    "idxs1_1 = np.where(regionMask > 0)[1][-1]\n",
    "\n",
    "idxs2_0 = np.where(regionMask > 0)[2][0]\n",
    "idxs2_1 = np.where(regionMask > 0)[2][-1]\n",
    "\n",
    "regionShape = ((idxs0_1 - idxs0_0),(idxs1_1 - idxs1_0),(idxs2_1 - idxs2_0))\n",
    "\n",
    "\n",
    "## load all doses\n",
    "allDoses = os.listdir(bedDoses)\n",
    "\n",
    "nImages = ptsToUse.shape[0]\n",
    "\n",
    "probe = sitk.ReadImage(os.path.join(bedDoses, allDoses[0]))\n",
    "\n",
    "imageShape = [*probe.GetSize()[::-1], nImages]\n",
    "\n",
    "doseData = np.zeros((*regionShape, nImages))\n",
    "print(doseData.shape)\n",
    "\n",
    "for n, img in tqdm(enumerate(ptsToUse)):\n",
    "    thisDose = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(nrrOutputDoses, \"{0}.nii\".format(img) ) ) )\n",
    "    doseData[:,:,:,n] = thisDose[idxs0_0:idxs0_1, idxs1_0:idxs1_1, idxs2_0:idxs2_1]\n",
    "#     doseData[:,:,:, n] *= regionMask## could suppress data outside?\n",
    "\n",
    "\n",
    "## Do a per-voxel t-test\n",
    "start = time.time()\n",
    "trueT = imagesTTest(doseData, statuses)\n",
    "trueMax = np.max(trueT)\n",
    "\n",
    "trueT_full = np.zeros(imageShape[:-1])\n",
    "trueT_full[idxs0_0:idxs0_1, idxs1_0:idxs1_1, idxs2_0:idxs2_1] = trueT\n",
    "\n",
    "\n",
    "outputT = sitk.GetImageFromArray(trueT_full)\n",
    "outputT.SetSpacing(probe.GetSpacing())\n",
    "outputT.SetOrigin(probe.GetOrigin())\n",
    "outputT.SetDirection(probe.GetDirection())\n",
    "sitk.WriteImage(outputT, \"test.nii\")\n",
    "\n",
    "\n",
    "## Now do a permutation test\n",
    "nPerm = 100\n",
    "permutationDist = np.zeros((nPerm,))\n",
    "gtCounts = 1.0\n",
    "\n",
    "# Slow single threaded works but is slow.\n",
    "for n in tqdm(range(nPerm)):\n",
    "    pstatuses = np.random.permutation(statuses)\n",
    "    permT = imagesTTest(doseData, pstatuses)\n",
    "    permutationDist[n] = np.max(permT)\n",
    "    if permutationDist[n] >= trueMax:\n",
    "        gtCounts += 1.0\n",
    "\n",
    "\n",
    "plt.figure(1, figsize=(16,9))\n",
    "plt.hist(permutationDist)\n",
    "plt.xlabel(\"Maximum t-value\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.axvline(trueMax)\n",
    "\n",
    "\n",
    "plt.figure(2, figsize=(16,9))\n",
    "plt.imshow(trueT_full[50,:,:])\n",
    "plt.show()\n",
    "\n",
    "print(\"Global p: {0}\".format(gtCounts/nPerm))\n",
    "permutationDist = np.sort(permutationDist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
